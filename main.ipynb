{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instala bibliotecas necess√°rias e importa m√≥dulos essenciais.\n",
        "\n"
      ],
      "metadata": {
        "id": "fdfFPEJL3CLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rszAxEbZOA43"
      },
      "outputs": [],
      "source": [
        "!pip install -q unsloth[colab-new] faiss-cpu sentence-transformers datasets accelerate trl peft transformers\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from transformers import pipeline\n",
        "from transformers import TrainingArguments\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "from datetime import date, timedelta"
      ],
      "metadata": {
        "id": "X1lx49AcLtBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7E3NuKW6Lyjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyGzkc5ez3a"
      },
      "source": [
        "# Download e explora√ß√£o inicial dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CuxJtGggAxGf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pubmedqa/pubmedqa.git\n",
        "\n",
        "file_path = 'pubmedqa/data/ori_pqal.json'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "sample_key = list(data.keys())[0]\n",
        "print(f\"\\nCampos dispon√≠veis: {list(data[sample_key].keys())}\\n\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Explora√ß√£o de dados - PubMedQA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, key in enumerate(list(data.keys())[:3]):\n",
        "    item = data[key]\n",
        "\n",
        "    print(f\"\\nExemplo {i+1} | ID: {key}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Question: {item.get('QUESTION', 'N/A')}\")\n",
        "\n",
        "    context = \" \".join(item.get('CONTEXTS', []))\n",
        "    print(f\"Context: {context[:300]}...\")\n",
        "\n",
        "    print(f\"Labels: {item.get('LABELS', 'N/A')}\")\n",
        "    print(f\"Decision: {item.get('final_decision', 'N/A')}\")\n",
        "    print(f\"Answer: {item.get('LONG_ANSWER', 'N/A')[:200]}...\")\n",
        "    print(f\"Meshes: {item.get('MESHES', 'N/A')}\")\n",
        "    print(f\"Year: {item.get('YEAR', 'N/A')}\")\n",
        "    print(f\"Reasoning required pred: {item.get('reasoning_required_pred', 'N/A')}\")\n",
        "    print(f\"Reasoning free pred: {item.get('reasoning_free_pred', 'N/A')}\")\n",
        "\n",
        "print(f\"\\n\\nTotal de registros: {len(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFH2sIYarWe"
      },
      "source": [
        "# Pr√©-processamento - Limpeza, Normaliza√ß√£o e Anonimiza√ß√£o dos Textos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4fd06e94"
      },
      "outputs": [],
      "source": [
        "MAP_DECISION = {\n",
        "  \"yes\": \"SIM\",\n",
        "  \"no\": \"N√ÉO\",\n",
        "  \"maybe\": \"TALVEZ\"\n",
        "}\n",
        "\n",
        "\n",
        "def anonymize_text(text):\n",
        "    \"\"\"Remove dados sens√≠veis (LGPD/HIPAA compliance)\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'(Dr\\.|Dra\\.|Doctor|Prof\\.|MD)\\s+[A-Z][a-z]+(\\s+[A-Z][a-z]+)?', '[NOME]', text)\n",
        "    text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '[EMAIL]', text)\n",
        "    locations = r'(Israel|Denmark|Chile|Texas|France|United Kingdom|UK|USA|Pakistan|Karachi|Jordan|Japan|Australia|North Carolina|Washington)'\n",
        "    text = re.sub(locations, '[LOCAL]', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\b\\d{6,}\\b', '[ID]', text)\n",
        "    text = re.sub(r'\\b(19|20)\\d{2}\\b', '[ANO]', text)\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[URL]', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "  if not text:\n",
        "    return \"\"\n",
        "  text = unicodedata.normalize(\"NFKC\", text)\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "  text = anonymize_text(text)\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "processed_docs = []\n",
        "\n",
        "for item in data.values():\n",
        "  question = clean_text(item.get(\"QUESTION\"))\n",
        "  context = clean_text(\" \".join(item.get(\"CONTEXTS\", [])))\n",
        "  answer = clean_text(item.get(\"LONG_ANSWER\", \"\"))\n",
        "  decision = MAP_DECISION.get(item.get(\"final_decision\", \"\"), \"\")\n",
        "\n",
        "\n",
        "  if question and context:\n",
        "    processed_docs.append({\n",
        "      \"question\": question,\n",
        "      \"context\": context,\n",
        "      \"answer\": answer,\n",
        "      \"decision\": decision,\n",
        "      \"year\": item.get(\"YEAR\")\n",
        "    })\n",
        "\n",
        "\n",
        "print(len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando conjunto de dados em portugu√™s para treino de tradu√ß√£o"
      ],
      "metadata": {
        "id": "eOou-BxIaFMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/diegosdomingos/tech-challenge-3.git\n",
        "\n",
        "file_path = 'tech-challenge-3/data/language_alignment_pt.jsonl'\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/rag/language_alignment_pt.json\",  #Alterar quando o dataset j√° estiver na main\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "\n",
        "def messages_to_text(example):\n",
        "    text = \"\"\n",
        "    for msg in example[\"messages\"]:\n",
        "        if msg[\"role\"] == \"system\":\n",
        "            text += f\"<<SYS>>\\n{msg['content']}\\n<</SYS>>\\n\\n\"\n",
        "        elif msg[\"role\"] == \"user\":\n",
        "            text += f\"[INST] {msg['content']} [/INST]\\n\"\n",
        "        elif msg[\"role\"] == \"assistant\":\n",
        "            text += msg[\"content\"]\n",
        "    return {\"text\": text}\n",
        "\n",
        "dataset = dataset.map(\n",
        "    messages_to_text,\n",
        "    batched=False,\n",
        "    remove_columns=[\"messages\"]\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "Q3r9Q4rFGh0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estrutura√ß√£o de Documentos para RAG (Recupera√ß√£o + Gera√ß√£o)\n",
        "## - Cria textos formatados unificando quest√£o, contexto e resposta para busca sem√¢ntica."
      ],
      "metadata": {
        "id": "CN9H1ot25hIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_documents = []\n",
        "\n",
        "for d in processed_docs:\n",
        "  text = f\"\"\"\n",
        "  Pergunta cient√≠fica:\n",
        "  {d['question']}\n",
        "\n",
        "\n",
        "  Evid√™ncia:\n",
        "  {d['context']}\n",
        "\n",
        "\n",
        "  Conclus√£o:\n",
        "  {d['answer']}\n",
        "  \"\"\"\n",
        "  rag_documents.append(text.strip())\n",
        "\n",
        "\n",
        "len(rag_documents)"
      ],
      "metadata": {
        "id": "jdL40-3R5nXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gera√ß√£o de Embeddings e Constru√ß√£o de √çndice FAISS"
      ],
      "metadata": {
        "id": "236_nIoK52PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embeddings = embedder.encode(rag_documents, show_progress_bar=True)\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/drive/MyDrive/rag', exist_ok=True)\n",
        "\n",
        "faiss.write_index(index, \"/content/drive/MyDrive/rag/medical_index.faiss\")\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json', 'w') as f:\n",
        "  json.dump(rag_documents, f)"
      ],
      "metadata": {
        "id": "hm0TXEBX56wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o do Modelo para Treinamento com LoRA\n",
        "## - Carrega modelo base e aplica adapta√ß√£o LoRA para reduzir custo de treino."
      ],
      "metadata": {
        "id": "l9uXJezHAtls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        ")"
      ],
      "metadata": {
        "id": "vaTkGNFE8NhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento Supervisionado do Assistente M√©dico em Portugu√™s"
      ],
      "metadata": {
        "id": "-rgHPIbcaTwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    args=training_args,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "sefogQu3LnHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autentica√ß√£o e Upload do Modelo Treinado no HuggingFace"
      ],
      "metadata": {
        "id": "mWe9atPtaZ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carregar env\n",
        "ENV_PATH = \"/content/drive/MyDrive/token-hf/env\"\n",
        "load_dotenv(ENV_PATH)\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "HF_REPO = f\"{HF_USER_REPO}/assistente-medico-lora\"\n",
        "\n",
        "model.push_to_hub(HF_REPO)\n",
        "tokenizer.push_to_hub(HF_REPO)"
      ],
      "metadata": {
        "id": "8WSXHwDBXptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o da Pipeline de Gera√ß√£o + Prompt do Assistente M√©dico"
      ],
      "metadata": {
        "id": "vDpkA6Dla3rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "Voc√™ √© um assistente m√©dico virtual.\n",
        "Responda sempre em portugu√™s, com linguagem clara, emp√°tica e baseada em evid√™ncias cient√≠ficas.\n",
        "\n",
        "\n",
        "Regras:\n",
        "- N√£o invente informa√ß√µes.\n",
        "- Se n√£o houver evid√™ncia suficiente, diga isso explicitamente.\n",
        "- N√£o prescreva medicamentos nem indique tratamentos espec√≠ficos.\n",
        "- N√£o indique rem√©dios ou tratamentos.\n",
        "- Quando perguntarem por algum rem√©dio, voc√™ deve responder: N√£o estou autorizado a prescrever medicamentos, por favor, consulte um m√©dico. <FIM>\n",
        "- Sempre cite a fonte da informa√ß√£o cient√≠fica\n",
        "\n",
        "Responda de forma objetiva e finalize sempre a primeira resposta objetiva com o texto: <FIM>\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json') as f:\n",
        "  docs = json.load(f)\n",
        "\n",
        "index = faiss.read_index('/content/drive/MyDrive/rag/medical_index.faiss')\n",
        "\n",
        "\n",
        "llm = pipeline(\n",
        "  \"text-generation\",\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        "  max_new_tokens=512,\n",
        "  temperature=0.0,\n",
        "  do_sample=False,\n",
        "  repetition_penalty=1.1,\n",
        "  return_full_text=False,\n",
        "  eos_token_id=tokenizer.eos_token_id\n",
        "  )\n",
        "\n",
        "def retrieve_context(question, k=3):\n",
        "  q_emb = embedder.encode([question])\n",
        "  _, idx = index.search(q_emb, k)\n",
        "  return \"\\n\\n\".join([docs[i] for i in idx[0]])\n",
        "\n",
        "def medical_chat(question):\n",
        "\n",
        "  # Adiciona <FIM> ao final da string `question` se n√£o estiver presente\n",
        "  if \"<FIM>\" not in question:\n",
        "    question += \" <FIM>\"\n",
        "\n",
        "  context = retrieve_context(question)\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "\n",
        "Contexto cient√≠fico relevante:\n",
        "{context}\n",
        "\n",
        "\n",
        "Pergunta: {question}\n",
        "Resposta:\n",
        "\"\"\"\n",
        "  output = llm(prompt)[0][\"generated_text\"]\n",
        "\n",
        "  # üîí corta tudo depois do token de fim\n",
        "  output = output.split(\"<FIM>\")[0]\n",
        "\n",
        "  return output.strip()"
      ],
      "metadata": {
        "id": "-rtcoC5nOohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cria√ß√£o de dataset de prontu√°rio (Fict√≠cio) com SQLite"
      ],
      "metadata": {
        "id": "Y-fFDBx0LMFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB_PATH = \"prontuarios.db\"\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS pacientes (\n",
        "    patient_id TEXT PRIMARY KEY,\n",
        "    nome TEXT,\n",
        "    data_nascimento TEXT,\n",
        "    idade INTEGER,\n",
        "    sexo TEXT,\n",
        "    alergias TEXT,\n",
        "    comorbidades TEXT\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS atendimentos (\n",
        "    atendimento_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    patient_id TEXT,\n",
        "    data_atendimento TEXT,\n",
        "    queixa_principal TEXT,\n",
        "    anamnese TEXT,\n",
        "    diagnostico TEXT,\n",
        "    conduta TEXT,\n",
        "    tratamentos_em_andamento TEXT,\n",
        "    exames_solicitados TEXT,\n",
        "    observacoes TEXT,\n",
        "    FOREIGN KEY(patient_id) REFERENCES pacientes(patient_id)\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "GZVUcyAWLQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Populando os dados fict√≠cios"
      ],
      "metadata": {
        "id": "p5XrRqtaO2C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nomes = [\n",
        "    \"Ana Paula Souza\", \"Ana Carolina Lima\", \"Bruno Silva\", \"Carlos Eduardo Rocha\",\n",
        "    \"Daniela Martins\", \"Eduardo Nogueira\", \"Fernanda Alves\", \"Gabriel Pacheco\",\n",
        "    \"Helena Ribeiro\", \"Igor Farias\", \"Juliana Torres\", \"Lucas Fernandes\",\n",
        "    \"Mariana Araujo\", \"Natalia Pacheco\", \"Otavio Nunes\", \"Paula Guedes\",\n",
        "    \"Rafael Moreira\", \"Sabrina Lopes\", \"Thiago Barros\", \"Vanessa Farias\",\n",
        "    \"William Teixeira\", \"Ana Beatriz Costa\"\n",
        "]\n",
        "\n",
        "diagnosticos = [\n",
        "    \"Hipertens√£o arterial sist√™mica\",\n",
        "    \"Diabetes mellitus tipo 2\",\n",
        "    \"Asma br√¥nquica\",\n",
        "    \"Infec√ß√£o do trato urin√°rio\",\n",
        "    \"Pneumonia adquirida na comunidade\",\n",
        "    \"Transtorno de ansiedade generalizada\",\n",
        "    \"Gastrite cr√¥nica\",\n",
        "    \"Enxaqueca cr√¥nica\"\n",
        "]\n",
        "\n",
        "alergias_lista = [\n",
        "    \"Dipirona\", \"Penicilina\", \"Sulfa\", \"Nenhuma conhecida\"\n",
        "]\n",
        "\n",
        "comorbidades_lista = [\n",
        "    \"Hipertens√£o\", \"Diabetes\", \"Dislipidemia\", \"Obesidade\", \"Nenhuma\"\n",
        "]\n",
        "\n",
        "def gerar_data_nascimento(idade):\n",
        "    hoje = date.today()\n",
        "    return hoje - timedelta(days=idade * 365)\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "for i, nome in enumerate(nomes, start=1):\n",
        "    idade = random.randint(18, 85)\n",
        "    patient_id = f\"PAT{i:04d}\"\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT OR IGNORE INTO pacientes\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        patient_id,\n",
        "        nome,\n",
        "        gerar_data_nascimento(idade).isoformat(),\n",
        "        idade,\n",
        "        random.choice([\"F\", \"M\"]),\n",
        "        random.choice(alergias_lista),\n",
        "        random.choice(comorbidades_lista)\n",
        "    ))\n",
        "\n",
        "    for _ in range(random.randint(1, 4)):\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO atendimentos (\n",
        "                patient_id,\n",
        "                data_atendimento,\n",
        "                queixa_principal,\n",
        "                anamnese,\n",
        "                diagnostico,\n",
        "                conduta,\n",
        "                tratamentos_em_andamento,\n",
        "                exames_solicitados,\n",
        "                observacoes\n",
        "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (\n",
        "            patient_id,\n",
        "            (date.today() - timedelta(days=random.randint(1, 1200))).isoformat(),\n",
        "            \"Dor, mal-estar e sintomas gerais\",\n",
        "            \"Paciente relata in√≠cio dos sintomas h√° alguns dias, sem fatores agravantes claros.\",\n",
        "            random.choice(diagnosticos),\n",
        "            \"Conduta expectante e acompanhamento ambulatorial\",\n",
        "            \"Uso cont√≠nuo de medica√ß√£o conforme prescri√ß√£o\",\n",
        "            \"Hemograma completo, glicemia, PCR\",\n",
        "            \"Paciente orientado quanto aos sinais de alarme\"\n",
        "        ))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "qiKMx2FwO039"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regras para consultar prontu√°rios"
      ],
      "metadata": {
        "id": "FALsGqFcO8Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_pacientes_por_nome(nome_parcial: str):\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT patient_id, nome, idade\n",
        "        FROM pacientes\n",
        "        WHERE LOWER(nome) LIKE LOWER(?)\n",
        "    \"\"\", (f\"%{nome_parcial}%\",))\n",
        "\n",
        "    resultados = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return resultados\n",
        "\n",
        "\n",
        "def carregar_prontuario(patient_id: str):\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT patient_id, nome, data_nascimento, idade, sexo, alergias, comorbidades\n",
        "        FROM pacientes\n",
        "        WHERE patient_id = ?\n",
        "    \"\"\", (patient_id,))\n",
        "    paciente = cursor.fetchone()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT data_atendimento, queixa_principal, anamnese, diagnostico,\n",
        "               conduta, tratamentos_em_andamento, exames_solicitados, observacoes\n",
        "        FROM atendimentos\n",
        "        WHERE patient_id = ?\n",
        "        ORDER BY data_atendimento DESC\n",
        "    \"\"\", (patient_id,))\n",
        "    atendimentos = cursor.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    if not paciente:\n",
        "        return \"Paciente n√£o encontrado.\"\n",
        "\n",
        "    texto = f\"\"\"\n",
        "PACIENTE\n",
        "ID: {paciente[0]}\n",
        "Nome: {paciente[1]}\n",
        "Data de nascimento: {paciente[2]}\n",
        "Idade: {paciente[3]}\n",
        "Sexo: {paciente[4]}\n",
        "Alergias: {paciente[5]}\n",
        "Comorbidades: {paciente[6]}\n",
        "\n",
        "ATENDIMENTOS:\n",
        "\"\"\"\n",
        "\n",
        "    for a in atendimentos:\n",
        "        texto += f\"\"\"\n",
        "Data: {a[0]}\n",
        "Queixa principal: {a[1]}\n",
        "Anamnese: {a[2]}\n",
        "Diagn√≥stico: {a[3]}\n",
        "Conduta: {a[4]}\n",
        "Tratamentos em andamento: {a[5]}\n",
        "Exames solicitados: {a[6]}\n",
        "Observa√ß√µes: {a[7]}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    return texto\n"
      ],
      "metadata": {
        "id": "ToC5i_h-TwaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM para entender a pergunta do prontu√°rio (Utiliza√ß√£o da mesma llm LLaMA)"
      ],
      "metadata": {
        "id": "HWadh2--T24A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extrair_intencao_e_nome(pergunta: str):\n",
        "    prompt = f\"\"\"\n",
        "Extraia informa√ß√µes estruturadas da pergunta abaixo.\n",
        "\n",
        "Pergunta:\n",
        "\"{pergunta}\"\n",
        "\n",
        "Responda APENAS em JSON, sem nenhum texto extra:\n",
        "\n",
        "{{\n",
        "  \"intencao\": \"consultar_prontuario\" | \"outra\",\n",
        "  \"nome_paciente\": string | null\n",
        "}}\n",
        "\n",
        "Responda de forma objetiva e finalize sempre a primeira resposta objetiva com o texto: <FIM>\n",
        "\n",
        "\"\"\"\n",
        "    resposta = medical_chat(prompt)\n",
        "\n",
        "    try:\n",
        "        json_str = re.search(r\"\\{.*\\}\", resposta, re.DOTALL).group()\n",
        "        return json.loads(json_str)\n",
        "    except:\n",
        "        return {\"intencao\": \"outra\", \"nome_paciente\": None}\n"
      ],
      "metadata": {
        "id": "QG5pxGL5T_V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router (Consulta prontu√°rio ou Dados de pubmedqa?)"
      ],
      "metadata": {
        "id": "cLOUuMUnPLp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estado = {\n",
        "    \"aguardando_escolha\": False,\n",
        "    \"opcoes\": []\n",
        "}\n",
        "\n",
        "def router_chat(pergunta: str):\n",
        "\n",
        "    # 1Ô∏è‚É£ Se o usu√°rio precisa escolher um paciente\n",
        "    if estado[\"aguardando_escolha\"]:\n",
        "        escolha = pergunta.strip().lower()\n",
        "\n",
        "        for pid, nome, idade in estado[\"opcoes\"]:\n",
        "            if escolha == pid.lower() or escolha == nome.lower():\n",
        "                estado[\"aguardando_escolha\"] = False\n",
        "                estado[\"opcoes\"] = []\n",
        "                prontuario = carregar_prontuario(pid)\n",
        "                return medical_chat(prontuario)\n",
        "\n",
        "        return medical_chat(\n",
        "            \"Ainda existem mais de um paciente poss√≠vel. \"\n",
        "            \"Pode informar o ID ou o nome completo?\"\n",
        "        )\n",
        "\n",
        "    # 2Ô∏è‚É£ Entender a pergunta\n",
        "    parsed = extrair_intencao_e_nome(pergunta)\n",
        "\n",
        "    if parsed[\"intencao\"] != \"consultar_prontuario\":\n",
        "        return medical_chat(pergunta)\n",
        "\n",
        "    nome = parsed[\"nome_paciente\"]\n",
        "\n",
        "    if not nome:\n",
        "        return medical_chat(\n",
        "            \"Claro üôÇ Qual √© o nome do paciente que voc√™ deseja consultar?\"\n",
        "        )\n",
        "\n",
        "    pacientes = buscar_pacientes_por_nome(nome)\n",
        "\n",
        "    if len(pacientes) == 0:\n",
        "        return medical_chat(\n",
        "            \"N√£o encontrei nenhum paciente com esse nome. \"\n",
        "            \"Voc√™ pode informar o nome completo?\"\n",
        "        )\n",
        "\n",
        "    if len(pacientes) > 1:\n",
        "        estado[\"aguardando_escolha\"] = True\n",
        "        estado[\"opcoes\"] = pacientes\n",
        "\n",
        "        lista = \"\\n\".join(\n",
        "            [f\"- {nome} (ID: {pid}, Idade: {idade})\"\n",
        "             for pid, nome, idade in pacientes]\n",
        "        )\n",
        "\n",
        "        return medical_chat(\n",
        "            \"Encontrei mais de um paciente com esse nome:\\n\\n\"\n",
        "            f\"{lista}\\n\\n\"\n",
        "            \"Qual deles voc√™ deseja consultar?\"\n",
        "        )\n",
        "\n",
        "    prontuario = carregar_prontuario(pacientes[0][0])\n",
        "    return medical_chat(prontuario)\n"
      ],
      "metadata": {
        "id": "LC1wu_4dUG6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testes de Consulta ao Assistente M√©dico com Exemplos\n"
      ],
      "metadata": {
        "id": "mt3Jqcl4SMF2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06713958"
      },
      "source": [
        "# Teste normal de consulta\n",
        "question = \"O que a literatura indica sobre o uso de aspirina em preven√ß√£o prim√°ria?\"\n",
        "print(f\"Resposta 1 (normal): {medical_chat(question)}\")\n",
        "\n",
        "# Testa restri√ß√£o\n",
        "question = \"Qual medicamento √© eficaz para pedra nos rins?\"\n",
        "print(f\"Resposta 2 (restri√ß√£o): {medical_chat(question)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAT Assistente"
      ],
      "metadata": {
        "id": "b449ih0OGNia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Assistente M√©dico iniciado\")\n",
        "print(\"Digite 'sair' para encerrar\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Voc√™: \").strip()\n",
        "\n",
        "    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
        "        print(\"Assistente: Sess√£o encerrada.\")\n",
        "        break\n",
        "\n",
        "    resposta = router_chat(user_input)\n",
        "    print(f\"Assistente: {resposta}\\n\")\n"
      ],
      "metadata": {
        "id": "o3v0HtQ3GSCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aRFH2sIYarWe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}